---
title: "Object-Oriented Matplotlib Challenge"
subtitle: "Mastering the Four Stages of Data Visualization"
format:
  html: default
execute:
  echo: true
  eval: true
---

# 🎯 Object-Oriented Matplotlib Challenge - The Four Stages of Data Visualization

::: {.callout-important}
## 📊 Challenge Requirements
- Complete all discussion questions for the four stages of visualization
- Create professional visualizations using object-oriented matplotlib
- Demonstrate mastery of the Grammar of Graphics
- See [Student Analysis Section](#student-analysis-section) for detailed requirements
:::

## The Problem: Mastering Object-Oriented Matplotlib Through the Four Stages

**Core Question:** How can we create compelling, professional data visualizations using object-oriented matplotlib and the four stages of visualization?

**The Challenge:** Real-world data visualization requires more than just plotting data - it requires a systematic approach that transforms raw data into compelling stories. The four stages framework provides a proven methodology for creating visualizations that inform, persuade, and inspire action.

**Our Approach:** We'll work with baseball stadium data to investigate whether Coors Field in Denver, Colorado is truly the most run-friendly ballpark in Major League Baseball. This investigation will take us through all four stages of visualization, demonstrating object-oriented matplotlib techniques along the way.

::: {.callout-warning}
## ⚠️ AI Partnership Required

This challenge pushes boundaries intentionally. You'll tackle problems that normally require weeks of study, but with Cursor AI as your partner (and your brain keeping it honest), you can accomplish more than you thought possible.

**The new reality:** The four stages of competence are Ignorance → Awareness → Learning → Mastery. AI lets us produce Mastery-level work while operating primarily in the Awareness stage. I focus on awareness training, you leverage AI for execution, and together we create outputs that used to require years of dedicated study.
:::

## The Four Stages of Data Visualization

The four essential stages for creating effective visualizations are:

1. **Stage 1: Declaration of Purpose** - Define your message and audience
2. **Stage 2: Curation of Content** - Gather and create all necessary data
3. **Stage 3: Structuring of Visual Mappings** - Choose geometry and aesthetics
4. **Stage 4: Formatting for Your Audience** - Polish for professional presentation

## Data and Business Context

We analyze Major League Baseball stadium data to investigate whether Coors Field in Denver, Colorado is truly the most run-friendly ballpark. This dataset is ideal for our analysis because:

- **Real Business Question:** Sports analysts and fans want to understand stadium effects on scoring
- **Clear Hypothesis:** High altitude should make Coors Field more run-friendly
- **Multiple Metrics:** We can analyze both total runs and home runs
- **Visualization Practice:** Perfect for demonstrating all four stages of visualization

## Data Loading and Initial Exploration

Let's start by loading the baseball data and understanding what we're working with.

```{python}
#| label: load-data
#| echo: true
#| message: false
#| warning: false

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
#import seaborn as sns

# Load 2010 baseball season data
df2010 = pd.read_csv("baseball10.csv")

# Load 2021 baseball season data for comparison
df2021 = pd.read_csv("baseball21.csv")

print("2010 data shape:", df2010.shape)
print("2021 data shape:", df2021.shape)
print("\n2010 data columns:", df2010.columns.tolist())
print("\nFirst few rows of 2010 data:")
print(df2010.head())
```

::: {.callout-note}
## 💡 Understanding the Data

**Baseball Game Data:** Contains information about each game, including:
- `home`: Home team (3-letter code)
- `visiting`: Visiting team (3-letter code)
- `homeScore`: Runs scored by home team
- `visScore`: Runs scored by visiting team
- `homeHR`: Home runs by home team
- `visHR`: Home runs by visiting team
- `date`: Game date

**Business Questions We'll Answer:**
1. Is Coors Field (COL) the most run-friendly ballpark in 2010?
2. How does this change in 2021?
3. What's the difference between total runs and home runs by stadium?
:::

## Stage 1: Declaration of Purpose

**Mental Model:** Start with a clear message and bold title that states your recommendation.

Our purpose is to investigate whether Coors Field in Denver, Colorado is truly the most run-friendly baseball stadium in Major League Baseball.

::: {.callout-important}
## 🤔 Discussion Questions: Stage 1 - Declaration of Purpose

**Question 1: Hypothesis Formation**
- Why might high altitude affect baseball performance?  Is Coors Field affected by high altitude?


**Answer:**

- **High Altitude Effect:** At high altitudes the air is less dense. This lowers drag on the baseball, so batted balls travel farther. Pitch movement also decreases, making breaking balls easier to hit. Together this usually means more home runs and more total runs.

- **Coors Field:** Coors Field is in Denver (about 5,280 feet above sea level). Because of the thin air, it is known as a **run-friendly** ballpark and we expect higher scoring there than at most other stadiums.
:::


## Stage 2: Curation of Content

**Mental Model:** Gather and create all the data you need to support your message.

Let's aggregate the data to get average runs per stadium:

```{python}
#| label: stage-2-content
#| echo: true

# Stage 2: Curation of Content
# Aggregate data to get average runs per stadium

# Process 2010 data
avgDF_2010 = (df2010
    .assign(totalRuns = lambda df: df.homeScore + df.visScore)
    .assign(totalHR = lambda df: df.homeHR + df.visHR)
    .drop(columns = ['date', 'visiting'])
    .groupby(['home'], as_index=False)
    .mean()
)

# Process 2021 data
avgDF_2021 = (df2021
    .assign(totalRuns = lambda df: df.homeScore + df.visScore)
    .assign(totalHR = lambda df: df.homeHR + df.visHR)
    .drop(columns = ['date', 'visiting'])
    .groupby(['home'], as_index=False)
    .mean()
)

print("2010 Stadium Averages (Top 5):")
print(avgDF_2010.head())
print("\n2021 Stadium Averages (Top 5):")
print(avgDF_2021.head())
```

::: {.callout-important}
## 🤔 Discussion Questions: Stage 2 - Curation of Content

**Question 1: Data Aggregation Strategy**
- How many games are in the dataset? Why do we aggregate individual games into stadium averages before we start the visualization process?


**Answer:**

- **Dataset Size:**  
  The 2010 dataset includes **2,430 games**, and the 2021 dataset includes **2,429 games**. Each row represents a single Major League Baseball game.

- **Why Aggregate:**  
  Aggregating game-level data into **average runs per stadium** helps simplify complex raw data into meaningful comparisons.  
  Instead of analyzing thousands of rows, aggregation summarizes performance by stadium, allowing us to clearly see which ballparks tend to produce **higher scoring games**.  

  This is especially important because teams play many home games—averaging the data removes random variation and highlights **stadium effects** rather than single-game outcomes.

:::






## Stage 3: Structuring of Visual Mappings

**Mental Model:** Choose the right geometry and aesthetics to effectively communicate your message.

Let's explore different visual approaches:

```{python}
#| label: stage-3-mapping-exploration
#| echo: true

# Stage 3: Structuring of Visual Mappings
# Explore different geometries and aesthetics

# Sort data for better visualization
avgDF_2010_sorted = avgDF_2010.sort_values('totalRuns', ascending=True)

# Create figure with subplots to compare approaches
fig, axes = plt.subplots(2, 2, figsize=(8, 6))

# Approach 1: Scatter plot (not ideal for categorical data)
axes[0,0].scatter(avgDF_2010_sorted.home, avgDF_2010_sorted.totalRuns)
axes[0,0].set_title("Approach 1: Scatter Plot")
axes[0,0].set_xlabel("Stadium")
axes[0,0].set_ylabel("Average Runs")

# Approach 2: Horizontal bar chart (better for categorical data)
axes[0,1].barh(avgDF_2010_sorted.home, avgDF_2010_sorted.totalRuns)
axes[0,1].set_title("Approach 2: Horizontal Bar Chart")
axes[0,1].set_xlabel("Average Runs")
axes[0,1].set_ylabel("Stadium")

# Approach 3: Vertical bar chart
axes[1,0].bar(avgDF_2010_sorted.home, avgDF_2010_sorted.totalRuns)
axes[1,0].set_title("Approach 3: Vertical Bar Chart")
axes[1,0].set_xlabel("Stadium")
axes[1,0].set_ylabel("Average Runs")
axes[1,0].tick_params(axis='x', rotation=45)

# Approach 4: Highlight Colorado
colorado_colors = ["darkorchid" if stadium == "COL" else "lightgrey" 
                   for stadium in avgDF_2010_sorted.home]
axes[1,1].barh(avgDF_2010_sorted.home, avgDF_2010_sorted.totalRuns, color=colorado_colors)
axes[1,1].set_title("Approach 4: Highlight Colorado")
axes[1,1].set_xlabel("Average Runs")
axes[1,1].set_ylabel("Stadium")

plt.tight_layout()
plt.show()
```

::: {.callout-important}
## 🤔 Discussion Questions: Stage 3 - Structuring of Visual Mappings

**Question 1: Geometry Choices**
- Why is a horizontal bar chart better than a scatter plot for this data?
- When would you choose a vertical bar chart over horizontal?

**Answer:**

- **Horizontal bar > scatter here:** 
Stadiums are categories. Bars encode value by **length/position**, which is easy to compare. A scatter plot forces many text labels on an axis and is harder to read for categories.

- **When to use vertical bars:**
 Use vertical bars when category names are **short** or there are **few** of them, or when the audience expects **left-to-right** growth (e.g., time, rank).



**Question 2: Aesthetic Mappings**
- What does the color highlighting accomplish in Approach 4?
- How does position (x/y) compare to color for encoding data?

**Answer:**

- **Color highlight (COL):**
 Color draws attention to our focus stadium **without changing** the scale. It guides the eye to the main story (Colorado).

- **Position vs color:** 
**Position** on an axis is the **most accurate** way to encode magnitude. **Color** is supportive—good for emphasis or grouping, but not a substitute for position when showing values.

::: 

## Stage 4: Formatting for Your Audience

**Mental Model:** Polish your visualization for professional presentation.

Let's create a publication-ready visualization:

```{python}
#| label: stage-4-final
#| echo: false
#| fig-cap: "Average runs per game by stadium in 2010 (Colorado highlighted)."

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# consistent style for business look
plt.style.use("seaborn-v0_8-whitegrid")

# Defensive: compute sorted table if it doesn't exist
try:
    avgDF_2010_sorted
except NameError:
    avgDF_2010_sorted = (
        avgDF_2010
        .sort_values("totalRuns", ascending=True)
        .reset_index(drop=True)
    )

# Colors: highlight Colorado
colors = ["darkorchid" if t == "COL" else "lightgrey"
          for t in avgDF_2010_sorted["home"]]

# Figure
fig, ax = plt.subplots(figsize=(9, 6), layout="constrained")
bars = ax.barh(avgDF_2010_sorted["home"], avgDF_2010_sorted["totalRuns"], color=colors)

# Titles / labels
ax.set_title("Colorado (COL) is the Most Run-Friendly Ballpark in 2010", fontsize=15, fontweight="bold", pad=14)
ax.set_xlabel("Average Runs Per Game")
ax.set_ylabel("Stadium (Home Team)")

# Legend
col_patch = plt.Rectangle((0,0), 1, 1, color="darkorchid", label="Colorado (COL)")
oth_patch = plt.Rectangle((0,0), 1, 1, color="lightgrey",  label="Other Stadiums")
ax.legend(handles=[col_patch, oth_patch], loc="lower right", frameon=True)

# Limits to leave room for annotation
xmax = 1.10 * float(avgDF_2010_sorted["totalRuns"].max())
ax.set_xlim(0, xmax)

# Annotate COL with offset + readable box
labels = avgDF_2010_sorted["home"].tolist()
if "COL" in labels:
    yidx = labels.index("COL")
    colorado_runs = float(avgDF_2010_sorted.loc[yidx, "totalRuns"])

    ax.annotate(
        f"COL: {colorado_runs:.2f} runs/game",
        xy=(colorado_runs, yidx),
        xytext=(colorado_runs + 0.4, yidx),
        va="center",
        bbox=dict(facecolor="white", alpha=0.9, edgecolor="none"),
        arrowprops=dict(arrowstyle="->", color="darkorchid", lw=1.6),
        color="darkorchid", fontweight="bold", fontsize=10,
    )

plt.show()
```

```{python}
#| label: stage-4-summary
#| echo: false

# Small printed summary (no code shown in output)
league_avg = float(avgDF_2010_sorted["totalRuns"].mean())
col_idx = avgDF_2010_sorted["home"].tolist().index("COL") if "COL" in avgDF_2010_sorted["home"].tolist() else None
col_val = float(avgDF_2010_sorted.loc[col_idx, "totalRuns"]) if col_idx is not None else None
uplift = (col_val / league_avg - 1.0) * 100 if col_val is not None else None

print(f"Summary (2010): COL average runs/game = {col_val:.2f}; league average = {league_avg:.2f}; COL is {uplift:.1f}% above league average.")
```


::: {.callout-important}
## 🤔 Discussion Questions: Stage 4 - Formatting for Your Audience

**Question 1: Professional Formatting**
- What elements make this visualization suitable for a business presentation?

**Answer:**

- **What makes it business-ready:**
  - **Message title** states the takeaway (not just “Bar chart”).
  - **Clear axes** with units: “Average Runs Per Game”.
  - **Sorted bars** so ranking is obvious.
  - **Minimal legend** or none; colors are purposeful (COL highlighted, others neutral).
  - **Consistent style** (grid is light; fonts readable; margins not cramped).
  - **Zero baseline** on the x-axis to keep lengths honest.
  - **Tidy labels** (no long tick labels overlapping; horizontal bars for many categories).


- **Is the annotation on the visualization helpful?  Can you fix its placement?**
  - Yes. It draws attention to **COL** and reinforces the message with a numeric value.
  
- **How I’d fix/position the annotation:**
  - **Offset the text** a bit to the right of the COL bar end (e.g., `xytext=(+0.4, 0)` in data coords).
  - **Align vertically** to the bar center (`va="center"`) and set a modest **fontsize**.
  - Use a short, clear label like **“COL: 10.6 runs/game”**.
  - Add a light **bbox** around the text (e.g., `bbox=dict(facecolor="white", alpha=0.8, edgecolor="none")`) so it’s readable over the grid.
  - Keep the **arrow simple** (→ `arrowprops=dict(arrowstyle='->', color='darkorchid', lw=1.5)`).
  - Ensure the annotation **doesn’t collide** with the figure edge by slightly increasing **x-limits** (e.g., `ax.set_xlim(0, max_val*1.1)`).

**Summary:** 
The final polish uses **position** for magnitude, **color** only for emphasis, a **message-first title**, and a **clean, readable layout**. The annotation is helpful once it’s offset, centered to the bar, and styled for legibility.
::: 

## Advanced Object-Oriented Techniques

**Mental Model:** Use object-oriented matplotlib to create complex, reusable visualizations.

Let's create a comprehensive comparison between 2010 and 2021:

```{python}
#| label: advanced-oo-techniques
#| echo: false

# Advanced Object-Oriented Techniques
# Create a comprehensive comparison visualization

# Prepare data for comparison
comparison_data = pd.merge(
    avgDF_2010[['home', 'totalRuns']].rename(columns={'totalRuns': 'runs_2010'}),
    avgDF_2021[['home', 'totalRuns']].rename(columns={'totalRuns': 'runs_2021'}),
    on='home', how='inner'
)

## TODO: Create the visualization

#| label: stage-5-final
#| echo: false
#| fig-cap: "Average runs per game by stadium — 2010 vs 2021 (Colorado highlighted, shared scale)."

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# consistent style for business look
plt.style.use("seaborn-v0_8-whitegrid")

# Build comparison_data defensively if missing
try:
    comparison_data
except NameError:
    comparison_data = (
        avgDF_2010[["home", "totalRuns"]].rename(columns={"totalRuns": "runs_2010"})
        .merge(
            avgDF_2021[["home", "totalRuns"]].rename(columns={"totalRuns": "runs_2021"}),
            on="home", how="inner"
        )
    )

# One consistent order (sort by 2010)
order = (comparison_data.sort_values("runs_2010", ascending=True)["home"].tolist())
comp_ord = comparison_data.set_index("home").loc[order].reset_index()

# Colors: highlight COL in both panels
colors_2010 = ["darkorchid" if t == "COL" else "lightgrey" for t in comp_ord["home"]]
colors_2021 = ["darkorchid" if t == "COL" else "lightgrey" for t in comp_ord["home"]]

# Shared x-limit for fair comparison
xmax = 1.10 * max(float(comp_ord["runs_2010"].max()), float(comp_ord["runs_2021"].max()))

# Two-panel figure (OO Matplotlib)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 7), sharey=True, layout="constrained")

# 2010
ax1.barh(comp_ord["home"], comp_ord["runs_2010"], color=colors_2010)
ax1.set_title("Average Runs per Game — 2010", pad=10, fontweight="bold")
ax1.set_xlabel("Average Runs per Game")
ax1.set_ylabel("Stadium (Home Team)")
ax1.set_xlim(0, xmax)
ax1.grid(True, axis="x", alpha=0.25)

# 2021
ax2.barh(comp_ord["home"], comp_ord["runs_2021"], color=colors_2021)
ax2.set_title("Average Runs per Game — 2021", pad=10, fontweight="bold")
ax2.set_xlabel("Average Runs per Game")
ax2.set_xlim(0, xmax)
ax2.grid(True, axis="x", alpha=0.25)

# Legend once
col_patch = plt.Rectangle((0,0), 1, 1, color="darkorchid", label="Colorado (COL)")
oth_patch = plt.Rectangle((0,0), 1, 1, color="lightgrey",  label="Other Stadiums")
ax2.legend(handles=[col_patch, oth_patch], loc="lower right", frameon=True)

# Annotate COL in both panels (if present)
labels = comp_ord["home"].tolist()
if "COL" in labels:
    yidx = labels.index("COL")

    # 2010
    v2010 = float(comp_ord.loc[yidx, "runs_2010"])
    ax1.annotate(
        f"COL: {v2010:.2f}",
        xy=(v2010, yidx),
        xytext=(v2010 + 0.35, yidx),
        va="center",
        bbox=dict(facecolor="white", alpha=0.9, edgecolor="none"),
        arrowprops=dict(arrowstyle="->", color="darkorchid", lw=1.6),
        color="darkorchid", fontweight="bold", fontsize=9,
    )

    # 2021
    v2021 = float(comp_ord.loc[yidx, "runs_2021"])
    ax2.annotate(
        f"COL: {v2021:.2f}",
        xy=(v2021, yidx),
        xytext=(v2021 + 0.35, yidx),
        va="center",
        bbox=dict(facecolor="white", alpha=0.9, edgecolor="none"),
        arrowprops=dict(arrowstyle="->", color="darkorchid", lw=1.6),
        color="darkorchid", fontweight="bold", fontsize=9,
    )

plt.suptitle("Run-Friendliness by Stadium: 2010 vs 2021 (Shared Scale, Colorado Highlighted)",
             y=1.02, fontsize=15, fontweight="bold")
plt.show()
```

```{python}
#| label: stage-5-summary
#| echo: false

# Small printed summary (no code shown)
rank2010 = comp_ord.sort_values("runs_2010", ascending=False).reset_index(drop=True)
rank2021 = comp_ord.sort_values("runs_2021", ascending=False).reset_index(drop=True)

def find_rank(df, col, team="COL"):
    if team in df["home"].tolist():
        return df.index[df["home"] == team][0] + 1, float(df.loc[df["home"] == team, col].iloc[0])
    return None, None

r2010, v2010 = find_rank(rank2010, "runs_2010")
r2021, v2021 = find_rank(rank2021, "runs_2021")

print(f"Comparison summary: In 2010, COL ranks #{r2010} at {v2010:.2f} runs/game; in 2021, COL ranks #{r2021} at {v2021:.2f} runs/game (shared scale).")
```

::: {.callout-important}
## 🤔 Discussion Questions: Advanced Object-Oriented Techniques

**Question 1: Using Subplot Layout**
- Create a two-facet visualization that shows the total runs for 2010 and 2021 for each stadium in a single figure.  Highlight Colorado in the visualization.

**Answer:**
- I built a **two-panel figure** (`fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)`), one panel per year.
- I used **horizontal bar charts** (best for many categorical labels).
- I kept a **single stadium order** (sorted by 2010) so both panels line up.
- I set a **common x-axis limit** (max across both years) so the left and right bars are comparable in absolute scale.
- I **highlighted Colorado** (`COL`) with **darkorchid** and used **lightgrey** for the others.
- I added a **simple legend** and a short **annotation** for COL in each panel.



**Question 2: Explanation of the Visualization**
- Ask AI To Add A Paragraph Here To Explain The Visualization
- Does AI come to the right conclusion?  If not, why not?

**Answer:**
- The figure shows **average runs per game** by stadium for **2010** (left) and **2021** (right).  
- Using the **same x-axis scale** lets us compare **absolute levels** between years, not just rank inside a year.  
- **Colorado (COL)** is highlighted. In 2010 it appears at/near the **top end**. In 2021 it remains a **top-tier run-friendly park** (exact rank depends on the data).  
- If an AI summary misses this (for example, it says the scales differ or ignores the common scale), then the conclusion would be off. The **shared scale** and **consistent ordering** are key to reading the figure correctly.

## Reflection

This challenge helped me practice the four stages of data visualization: defining purpose, curating data, choosing visual structure, and formatting for clarity.  
Through object-oriented Matplotlib, I learned how consistent scales and focused color choices strengthen communication, especially when comparing multi-year results.


:::

## Student Analysis Section: Mastering Object-Oriented Matplotlib {#student-analysis-section}

**Your Task:** Demonstrate your mastery of object-oriented matplotlib and the four stages of visualization through comprehensive analysis and creation of professional visualizations.

### Core Challenge: Four Stages Analysis

**For each stage, provide:**
- Clear, concise answers to all discussion questions
- Code examples when asked to do so
- Demonstration of object-oriented matplotlib techniques

### Professional Visualizations (For 100% Grade)

**Your Task:** Create a professional visualization and narrative that builds towards and demonstrates mastery of object-oriented matplotlib and the four stages framework.

**Create visualizations showing:**
- Stadium run-friendliness comparison between 2010 and 2021
- Focus on Colorado's performance relative to other stadiums
- Use object-oriented matplotlib techniques throughout

**Your visualizations should:**
- Use clear labels and professional formatting
- Demonstrate all four stages of visualization
- Be appropriate for a business audience
- Show mastery of object-oriented matplotlib
- Do not `echo` the code that creates the visualizations

## Getting Started: Repository Setup 🚀

::: {.callout-important}
## 📁 Getting Started

**Step 1:** Fork and clone this challenge repository: `https://github.com/flyaflya/dataVizChallenge`
- Fork it to your GitHub account, then clone it from your GitHub account to your local machine

**Step 2:** Set up your Python environment
- **Recommended:** Use your existing virtual environment from Tech Setup Challenge Part 2
  - Press `Ctrl+Shift+P` → "Python: Select Interpreter"
  - Navigate to your existing virtual environment (e.g., `your-previous-project/venv/Scripts/python.exe`)
  - Install additional packages: `pip install pandas numpy matplotlib seaborn`
- **Alternative:** Create a new virtual environment following [Quarto documentation](https://quarto.org/docs/projects/virtual-environments.html)

**Step 3:** You're ready to start! The data loading code and starter code for the visualizations are already provided in this file.

**Note:** This challenge uses the same `index.qmd` file you're reading right now - you'll edit it to complete your analysis.
:::

::: {.callout-warning}
## ⚠️ Cloud Storage Warning

**Avoid using Google Drive, OneDrive, or other cloud storage for Python projects!** These services can cause issues with package installations and virtual environment corruption. Keep your Python projects in a local folder like `C:\Users\YourName\Documents\` instead.
:::

::: {.callout-note}
## 🎯 Object-Oriented Matplotlib Philosophy

*Think of object-oriented matplotlib like directing a movie - you control every element (camera angles, lighting, actors) to create the perfect scene that tells your story.*
:::

::: {.callout-warning}
## 💾 Important: Save Your Work Frequently!

**Before you start:** Make sure to commit your work often using the Source Control panel in Cursor (Ctrl+Shift+G or Cmd+Shift+G). This prevents the AI from overwriting your progress and ensures you don't lose your work.

**Commit after each major step:**
- After completing each stage section
- After adding your visualizations
- After completing your advanced object-oriented techniques
- Before asking the AI for help with new code

**How to commit:**
1. Open Source Control panel (Ctrl+Shift+G)
2. Stage your changes (+ button)
3. Write a descriptive commit message
4. Click the checkmark to commit

*Remember: Frequent commits are your safety net!*
:::

## Grading Rubric 🎓

**85% Grade:** Complete discussion questions for all 4 stages with comprehensive, well-reasoned responses.

**100% Grade:** Complete all discussion questions plus create professional visualizations as requested that demonstrate mastery of the four stages framework.

## Submission Checklist ✅

**Minimum Requirements (Required for Any Points):**

- [ ] Fork repository named "dataVizChallenge" to your GitHub account
- [ ] Clone repository locally using Cursor (or VS Code)
- [ ] Completed discussion questions for at least 3 of the 4 stages
- [ ] Document rendered to HTML successfully
- [ ] HTML files uploaded to your repository
- [ ] GitHub Pages enabled and working
- [ ] Site accessible at `https://[your-username].github.io/dataVizChallenge/`

**85% Grade Requirements:**

- [ ] Complete discussion questions for all 4 stages
- [ ] Comprehensive, well-reasoned responses showing deep understanding

**100% Grade Requirements:**

- [ ] All discussion questions completed with professional quality
- [ ] Professional visualization as requested demonstrating four stages framework

**Report Quality (Critical for Higher Grades):**

- [ ] Professional writing style (no AI-generated fluff)
- [ ] Concise analysis that gets to the point
- [ ] Clear demonstration of object-oriented matplotlib 